{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.cluster import kmeans_plusplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = \"/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/DATASETS/real_data/Data_without_labels\"\n",
    "# transf_path = \"/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/DATASETS/real_data/P_adic_transformed_data/transformed_data\"\n",
    "# out_path = \"/Users/schmuck/Library/CloudStorage/OneDrive-IndianaUniversity/PhD/DATASETS/real_data/Data_without_labels/\"\n",
    "\n",
    "base_path = \"/u/parishar/nobackup/DATASETS/exp_data/raw_data/\"\n",
    "\n",
    "\n",
    "file_list = [\"pollen_raw.csv\", \"darmanis_raw.csv\", \"usoskin_raw.csv\", \"mouse_pan.csv\", \n",
    "            \"Muraro_raw.csv\", \"QSLimb_raw.csv\", \"QSTrachea_raw.csv\", \"QSLung_raw.csv\", \"QSDiaphragm_raw.csv\", \n",
    "             \"Q10XSpleen_raw.csv\"]\n",
    "\n",
    "data_list = [\"Pollen\", \"Darmanis\", \"Usoskin\", \"Mouse_pan\", \"Muraro\", \"QSLimb\", \"QSTrachea\", \"QSLung\", \n",
    "             \"QSDiaphragm\", \"Q10XSpleen\"]\n",
    "\n",
    "label_list = [\"labels_pollen.csv\", \"labels_darmanis.csv\", \"labels_usoskin.csv\", \n",
    "              \"labels_mouse_pan.csv\", \"labels_Muraro.csv\", \"labels_QSLimb.csv\", \"labels_QSTrachea.csv\", \n",
    "              \"labels_QSLung.csv\", \"labels_QSDiaphragm.csv\",\n",
    "              \"labels_Q10XSpleen.csv\"]\n",
    "\n",
    "data_num_clusters = {\"Usoskin\": 4, \"Pollen\": 11, \n",
    "             \"Mouse_pan\": 13, \"Darmanis\": 8, \"Muraro\": 9,\n",
    "             \"QSLimb\": 6, \"QSLung\": 11, \"Q10XSpleen\": 5, \n",
    "             \"QSTrachea\": 4, \"QSDiaphragm\": 5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, label_name):\n",
    "    \n",
    "    file_path = os.path.join(base_path, file_name)\n",
    "    data = pd.read_csv(file_path, sep=\",\", header=None)\n",
    "    labels = pd.read_csv(os.path.join(base_path, label_name), header=None)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def pre_process_data(data, labels):\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    print(\"Data Shape: \", data.shape)\n",
    "\n",
    "    # Remove genes expressed in less than 1% of cell\n",
    "    gene_expr_sum = np.sum(data, axis=0)\n",
    "    limit = np.ceil(0.01 * data.shape[0])\n",
    "    wch_genes = np.where(gene_expr_sum < limit)[0]\n",
    "    \n",
    "    if len(wch_genes) > 0:\n",
    "        print(\"Genes to be removed:\", len(wch_genes))\n",
    "        data = np.delete(data, wch_genes, 1)\n",
    "\n",
    "    rsum = np.sum(data, 1)\n",
    "    wch_cells = np.where(rsum < 100)[0]\n",
    "    \n",
    "\n",
    "    if len(wch_cells) > 0:\n",
    "        print(\"Cell to be removed: \", len(wch_cells))\n",
    "        data = np.delete(data, wch_cells, 0)\n",
    "        labels = np.delete(labels, wch_cells, 0)\n",
    "\n",
    "\n",
    "    # Library size normalization\n",
    "    data = (data/np.sum(data, 1)[:, None]) * np.median(np.sum(data, 1))\n",
    "    \n",
    "    labels = np.array(labels).reshape(data.shape[0],)\n",
    "    # data = pd.DataFrame(data)\n",
    "\n",
    "    print(\"Data Shape: \", data.shape, len(labels))\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  Pollen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape:  (299, 21468)\n",
      "Genes to be removed: 1516\n",
      "Data Shape:  (299, 19952) 299\n",
      "Processing:  Darmanis\n",
      "Data Shape:  (420, 21516)\n",
      "Genes to be removed: 2094\n",
      "Data Shape:  (420, 19422) 420\n",
      "Processing:  Usoskin\n",
      "Data Shape:  (622, 19532)\n",
      "Genes to be removed: 1509\n",
      "Data Shape:  (622, 18023) 622\n",
      "Processing:  Mouse_pan\n",
      "Data Shape:  (1884, 14878)\n",
      "Genes to be removed: 2978\n",
      "Data Shape:  (1884, 11900) 1884\n",
      "Processing:  Muraro\n",
      "Data Shape:  (2122, 19046)\n",
      "Genes to be removed: 3723\n",
      "Data Shape:  (2122, 15323) 2122\n",
      "Processing:  QSLimb\n",
      "Data Shape:  (1090, 23341)\n",
      "Genes to be removed: 6665\n",
      "Data Shape:  (1090, 16676) 1090\n",
      "Processing:  QSTrachea\n",
      "Data Shape:  (1350, 23341)\n",
      "Genes to be removed: 4944\n",
      "Data Shape:  (1350, 18397) 1350\n",
      "Processing:  QSLung\n",
      "Data Shape:  (1676, 23341)\n",
      "Genes to be removed: 6077\n",
      "Data Shape:  (1676, 17264) 1676\n",
      "Processing:  QSDiaphragm\n",
      "Data Shape:  (870, 23341)\n",
      "Genes to be removed: 7528\n",
      "Data Shape:  (870, 15813) 870\n",
      "Processing:  Q10XSpleen\n",
      "Data Shape:  (9552, 23341)\n",
      "Genes to be removed: 13626\n",
      "Data Shape:  (9552, 9715) 9552\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(9)\n",
    "seeds = np.random.choice(2000, 200, replace=False).reshape(10, 20)\n",
    "\n",
    "num_rep = 20\n",
    "\n",
    "temp_data = []\n",
    "temp_indices = []\n",
    "temp_run = []\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "\n",
    "    print(\"Processing: \", data_list[i])\n",
    "\n",
    "    file_name = file_list[i]\n",
    "    label_name = label_list[i]\n",
    "\n",
    "    # Load\n",
    "    data, labels = load_data(file_name, label_name)\n",
    "\n",
    "    # Preprocess\n",
    "    data, labels = pre_process_data(data, labels)\n",
    "\n",
    "    # Num clusters\n",
    "    num_clusters = data_num_clusters[data_list[i]]\n",
    "    \n",
    "    # path = os.path.join(std_path, file)\n",
    "    # std_data = np.array(pd.read_csv(path, low_memory=False), dtype=\"float32\")\n",
    "\n",
    "    # path = os.path.join(transformed_path, file)\n",
    "    # transformed_data = np.array(pd.read_csv(path, low_memory=False), dtype=\"float32\")\n",
    "    \n",
    "    for rep in range(num_rep):\n",
    "\n",
    "        _, indices = kmeans_plusplus(data, n_clusters=num_clusters, random_state=seeds[i, rep])\n",
    "        \n",
    "        temp_data.append(data_list[i])\n",
    "        temp_run.append(rep)\n",
    "        \n",
    "        temp_indices.append(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kpp_centroid_indices.csv\", \"w\") as myFile:\n",
    "    \n",
    "    myFile.write(\"Data\" + \",\" + \"Run\" + \",\" + \"Indices\" + \"\\n\")\n",
    "    \n",
    "    for i in range(len(temp_data)):\n",
    "        \n",
    "        ind = \"\"\n",
    "        \n",
    "        for j in range(len(temp_indices[i])):\n",
    "            \n",
    "            if j < len(temp_indices[i])-1:\n",
    "                ind += str(temp_indices[i][j]) + \"+\"  \n",
    "            else:\n",
    "                ind += str(temp_indices[i][j])\n",
    "        \n",
    "        # print(temp_data[i] + \",\" + str(temp_run[i]) + \",\" + ind)\n",
    "        \n",
    "        if i < len(temp_data)-1:\n",
    "            myFile.write(temp_data[i] + \",\" + str(temp_run[i]) + \",\" + ind + \"\\n\")\n",
    "        else:\n",
    "            myFile.write(temp_data[i] + \",\" + str(temp_run[i]) + \",\" + ind )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
